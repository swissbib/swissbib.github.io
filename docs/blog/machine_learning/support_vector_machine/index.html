<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=apple-mobile-web-app-capable content="yes"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#50bf9e"><meta name=generator content="Hugo 0.74.3"><meta name=robots content="index, follow"><title>What Humans Learn about the Data from a Support Vector Machine | swissbib data blog</title><link rel=canonical href=https://swissbib.github.io/blog/machine_learning/support_vector_machine/><meta name=description content="using Support Vector Machine"><meta name=author content="project swissbib"><link rel=manifest href=/manifest.json><meta property="og:title" content="What Humans Learn about the Data from a Support Vector Machine"><meta property="og:site_name" content="swissbib data blog"><meta property="og:description" content="using Support Vector Machine"><meta property="og:type" content="article"><meta property="og:url" content="https://swissbib.github.io/blog/machine_learning/support_vector_machine/"><meta property="article:published_time" content="2020-08-20T16:07:50+02:00"><meta property="article:modified_time" content="2020-08-20T16:07:50+02:00"><meta property="article:section" content="blog"><meta property="article:tag" content="support vector machine"><meta property="article:tag" content="english"><meta property="article:tag" content="2020"><meta name=twitter:card content="summary"><meta name=twitter:title content="What Humans Learn about the Data from a Support Vector Machine"><meta name=twitter:description content="using Support Vector Machine"><meta name=twitter:site content="@https://twitter.com/swissbib"><meta name=twitter:creator content="@https://twitter.com/swissbib"><meta name=news_keywords content="support vector machine,english,2020"><script type=application/ld+json>{"headline":"What Humans Learn about the Data from a Support Vector Machine","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/image/logo.min.svg"},"name":"project swissbib"},"author":{"@type":"Person","name":"project swissbib"},"description":"using Support Vector Machine","name":"swissbib data blog","@type":"BlogPostingblog","wordCount":1418,"mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/swissbib.github.io\/blog\/machine_learning\/support_vector_machine\/"},"@context":"http://schema.org","dateCreated":"2020-08-20T16:07:50+02:00","dateModified":"2020-08-20T16:07:50+02:00","url":"https://swissbib.github.io/blog/machine_learning/support_vector_machine/"}</script><link rel=preload href=/index.json as=fetch crossorigin importance=low><link rel=stylesheet href=/css/index.min.d038f1a09fadf7102851d162968e2191579591b1a81db498d110a28635df30bd382fcb6f9e1c9be70b999bcb7fc7e2c5f671d7f5dd9e186f91c4de01dfd9ecd5.css media=none onload="if(media!='all')media='all'"><noscript><link rel=stylesheet href=/css/index.min.d038f1a09fadf7102851d162968e2191579591b1a81db498d110a28635df30bd382fcb6f9e1c9be70b999bcb7fc7e2c5f671d7f5dd9e186f91c4de01dfd9ecd5.css media=screen></noscript><style>html{opacity:0}</style><script type=text/javascript src=/index.min.js defer></script><script>if(window.localStorage.color){document.documentElement.style.setProperty("--theme-color",window.localStorage.color);}
if(window.localStorage.dark==="true"){document.documentElement.classList.add("dark");}</script></head><body><a href=#top class=scroll-up role=button><span class=sr-only>Scroll to top</span><svg width="30" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M16 6.59375l-.71875.6875-12.5 12.5 1.4375 1.4375L16 9.4375 27.78125 21.21875l1.4375-1.4375-12.5-12.5L16 6.59375z"/></svg></a><header id=header><input class=hamburger role=button type=checkbox aria-label="Menu Button">
<a class=icon aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 25 28"><g class="svg-menu-toggle"><path class="bar" d="M20.945 8.75c0 .69-.5 1.25-1.117 1.25H3.141c-.617.0-1.118-.56-1.118-1.25s.5-1.25 1.118-1.25h16.688C20.445 7.5 20.945 8.06 20.945 8.75z"/><path class="bar" d="M20.923 15c0 .689-.501 1.25-1.118 1.25H3.118C2.5 16.25 2 15.689 2 15s.5-1.25 1.118-1.25h16.687C20.422 13.75 20.923 14.311 20.923 15z"/><path class="bar" d="M20.969 21.25c0 .689-.5 1.25-1.117 1.25H3.164c-.617.0-1.118-.561-1.118-1.25s.5-1.25 1.118-1.25h16.688C20.469 20 20.969 20.561 20.969 21.25z"/></g></svg></a><a role=button class=logo href=https://swissbib.github.io/index.html><svg xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" enable-background="new 0 0 500 150" viewBox="0 0 388.97198 121.52146" height="121.52146" width="388.97198" id="Ebene_1"><defs id="defs77"/><g transform="translate(-59.79,-4.3615414)" id="g3"><g id="g5"><defs id="defs7"><polygon points="-22,325 -22,-85 -22,-85 573.273,-85 573.273,325" id="SVGID_1_"/></defs><clipPath id="SVGID_2_"><use height="100%" width="100%" y="0" x="0" style="overflow:visible" id="use11" overflow="visible" xlink:href="#SVGID_1_"/></clipPath><path style="fill:#fff" id="path15" d="m310.63 60.843c0 3.024-2.45 5.478-5.473 5.478-3.024.0-5.475-2.453-5.475-5.478.0-3.022 2.45-5.473 5.475-5.473 3.023.0 5.473 2.45 5.473 5.473z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path17" d="m171.77 60.67c0 3.023-2.453 5.477-5.477 5.477-3.023.0-5.473-2.453-5.473-5.477s2.45-5.473 5.473-5.473c3.024.0 5.477 2.449 5.477 5.473z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path19" d="m60.563 115.953c3.757 2.217 7.807 3.184 11.567 3.184 4.337.0 8-1.834 8-6.75.0-9.927-19.857-8.289-19.857-23.229.0-9.544 8.097-13.497 15.71-13.497 3.377.0 7.23.482 10.22 1.736l-.58 7.23C82.83 83.18 79.747 82.41 76.37 82.41c-3.567.0-7.517 1.637-7.517 6.263.0 10.317 19.857 8.004 19.857 22.847.0 9.737-7.423 14.363-16.197 14.363-4.53.0-8.77-.673-12.723-2.12l.773-7.81z" clip-path="url(#SVGID_2_)"/><polygon style="fill:#fff" id="polygon21" points="110.3,116.63 119.17,76.623 128.81,76.623 137.677,116.63 146.35,76.623 154.543,76.623 142.207,124.823 132.567,124.823 123.797,85.396 114.83,124.823 105.19,124.823 105.19,124.823 92.853,76.623 101.72,76.623" clip-path="url(#SVGID_2_)"/><polygon style="fill:#fff" id="polygon23" points="170.353,124.823 162.063,124.823 162.063,124.823 162.063,76.623 170.353,76.623" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path25" d="m180.953 115.953c3.76 2.217 7.81 3.184 11.567 3.184 4.34.0 8-1.834 8-6.75.0-9.927-19.853-8.289-19.853-23.229.0-9.544 8.096-13.497 15.71-13.497 3.373.0 7.23.482 10.22 1.736l-.58 7.23c-2.797-1.447-5.88-2.217-9.254-2.217-3.566.0-7.52 1.637-7.52 6.263.0 10.317 19.857 8.004 19.857 22.847.0 9.737-7.42 14.363-16.193 14.363-4.53.0-8.77-.673-12.724-2.12l.77-7.81z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path27" d="m216.33 115.953c3.76 2.217 7.807 3.184 11.567 3.184 4.335.0 8-1.834 8-6.75.0-9.927-19.856-8.289-19.856-23.229.0-9.544 8.097-13.497 15.713-13.497 3.374.0 7.229.482 10.218 1.736l-.578 7.23c-2.795-1.447-5.879-2.217-9.252-2.217-3.57.0-7.521 1.637-7.521 6.263.0 10.317 19.856 8.004 19.856 22.847.0 9.737-7.424 14.363-16.193 14.363-4.533.0-8.773-.673-12.723-2.12l.769-7.81z" clip-path="url(#SVGID_2_)"/><polygon style="fill:#fff" id="polygon29" points="309.25,124.823 300.96,124.823 300.96,124.823 300.96,76.623 309.25,76.623" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path31" d="m272.141 119.137c-8.457.0-9.928-12.27-9.928-18.607.0-7.036 1.54-18.119 9.928-18.119 8.482.0 9.542 11.857 9.542 18.119.0 6.074-1.35 18.607-9.542 18.607zm2.312-43.477c-5.88.0-9.641 3.18-12.051 7.713v-28.051h-8.285v46.697c0 10.061 2.482 23.863 17.976 23.863 15.527.0 18.46-15.326 18.46-25.354.0-10.408-2.991-24.868-16.1-24.868z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path33" d="m340.29 119.137c-8.457.0-9.93-12.27-9.93-18.607.0-7.036 1.543-18.119 9.93-18.119 8.479.0 9.54 11.857 9.54 18.119.0 6.074-1.347 18.607-9.54 18.607zm2.313-43.477c-5.88.0-9.64 3.18-12.05 7.713v-28.051h-8.29v46.697c0 10.061 2.484 23.863 17.978 23.863 15.529.0 18.46-15.326 18.46-25.354C358.7 90.12 355.713 75.66 342.603 75.66z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path35" d="m367.88 36.62c.003-.07.01-.138.013-.2-.003.062-.01.13-.013.2z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path37" d="m368.03 35.247c.029-.207.05-.41.08-.614-.03.204-.053.407-.08.614z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path39" d="m389.997 72.543c-.007-.003-.017-.006-.024-.01.007.004.017.007.024.01z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path41" d="m403.337 75.05c-.05.003-.1.003-.15.003.05.0.1.0.15-.003z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path43" d="m406.727 74.87c-.124.01-.243.017-.366.03.122-.009.242-.02.366-.03z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path45" d="m405.06 75c-.093.003-.189.007-.286.01.096-.003.193-.007.286-.01z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path47" d="m388.443 71.883c-.014-.006-.03-.016-.047-.023.017.007.034.017.047.023z" clip-path="url(#SVGID_2_)"/><path style="fill:#fdeb18" id="path49" d="m397.327 20.85c1.746.42 3.413.998 5.006 1.693 4.729-3.141 10.407-4.973 16.51-4.973 5.217.0 10.117 1.337 14.388 3.683-.591-.963-1.23-1.905-1.921-2.826-11.757-15.587-33.917-18.69-49.51-6.94-7.566 5.707-12.18 13.871-13.59 22.541.32-1.944.797-3.857 1.43-5.715 7.12-6.79 17.42-9.946 27.687-7.463z" clip-path="url(#SVGID_2_)"/><path style="fill:#2a245a" id="path51" d="m433.23 21.253c9.412 15.345 5.803 35.617-8.86 46.677-5.323 4.01-11.417 6.291-17.597 6.93l-.004.004c3.697 1.63 7.777 2.547 12.073 2.547 16.521.0 29.92-13.4 29.92-29.92C448.763 36.18 442.487 26.34 433.23 21.253z" clip-path="url(#SVGID_2_)"/><path style="fill:#cbba9f" id="path53" d="m402.333 22.543c13.03 5.71 20.507 20.104 17.044 34.417-1.85 7.653-6.51 13.88-12.604 17.899 6.18-.639 12.273-2.92 17.597-6.93 14.663-11.06 18.272-31.332 8.86-46.677-4.271-2.346-9.171-3.683-14.388-3.683-6.102.001-11.78 1.833-16.509 4.974z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path55" d="m406.36 74.9c-.431.039-.867.072-1.301.1.434-.027.871-.061 1.301-.1z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path57" d="m404.773 75.01c-.477.023-.956.04-1.437.04.481-.003.957-.017 1.437-.04z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path59" d="m406.727 74.87c.014-.003.03-.003.043-.007-.013.0-.03.004-.043.007z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path61" d="m403.187 75.053c-4.504.008-8.986-.84-13.189-2.51 4.165 1.657 8.642 2.523 13.189 2.51z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path63" d="m368.11 34.633c.029-.203.066-.402.1-.605-.033.202-.07.402-.1.605z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path65" d="m367.893 36.42c.04-.393.088-.783.138-1.173-.051.39-.098.78-.138 1.173z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path67" d="m374.87 60.99c-5.483-7.27-7.73-15.967-6.99-24.37-.517 5.67.323 11.543 2.75 17.144 3.62 8.356 10.083 14.596 17.767 18.096-5.177-2.36-9.86-6.006-13.527-10.87z" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path69" d="m389.973 72.533c-.513-.203-1.022-.424-1.529-.65.506.226 1.016.447 1.529.65z" clip-path="url(#SVGID_2_)"/><polygon style="fill:#fff" id="polygon71" points="406.77,74.863 406.773,74.859 406.77,74.863" clip-path="url(#SVGID_2_)"/><path style="fill:#fff" id="path73" d="m402.333 22.543c-1.593-.695-3.26-1.273-5.006-1.693-10.268-2.482-20.567.674-27.688 7.463-.633 1.857-1.109 3.771-1.43 5.715-.033.203-.07.402-.1.605-.03.204-.051.407-.08.614-.05.39-.098.78-.138 1.173-.003.062-.01.13-.013.2-.74 8.403 1.507 17.101 6.99 24.37 3.667 4.863 8.35 8.51 13.526 10.869.017.008.033.018.047.023.507.227 1.017.447 1.529.65.008.004.018.007.024.01 4.203 1.67 8.686 2.518 13.189 2.51.051.0.101.0.15-.003.48.0.96-.017 1.437-.04.097-.003.193-.007.286-.01.434-.027.87-.061 1.301-.1.123-.014.242-.021.366-.03.014-.003.03-.007.043-.007l.004-.004c6.094-4.02 10.754-10.246 12.604-17.899 3.466-14.313-4.011-28.706-17.041-34.416z" clip-path="url(#SVGID_2_)"/></g></g></svg><span class=sr-only>Logo</span></a><ul role=menubar class=top-menu><li role=menuitem class=top-menu-item><a href=/blog/>BLOG</a><ul class=sub-menu role=menu><li><a href=/blog/machine_learning/>MACHINE LEARNING</a></li></ul></li><li role=menuitem class=top-menu-item><a href=/categories>CATEGORIES</a></li><li role=menuitem class=top-menu-item><a href=/tags>TAGS</a></li></ul><div id=searchbox><label class=sr-only for=search>Search</label>
<input id=search type=text placeholder=Search spellcheck=true><svg width="20" class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="currentcolor" d="M19 3C13.488997 3 9 7.4889972 9 13 9 15.39499 9.8389508 17.588106 11.25 19.3125L3.28125 27.28125l1.4375 1.4375L12.6875 20.75C14.411894 22.161049 16.60501 23 19 23 24.511003 23 29 18.511003 29 13 29 7.4889972 24.511003 3 19 3zm0 2C23.430123 5 27 8.5698774 27 13 27 17.430123 23.430123 21 19 21 14.569877 21 11 17.430123 11 13 11 8.5698774 14.569877 5 19 5z"/></svg><section class=results></section></div><div id=scroll-indicator></div></header><section class="meta content with-background"><article><h1 class=title>What Humans Learn about the Data from a Support Vector Machine</h1><p>Machine Learning may look mystical, although it is based on the mathematical discipline of statistics. If the learning process is done with a fixed data set, Machine Learning can be structured into two distinct groups of tasks, supervised and unsupervised learning. In supervised learning, the artificial machine is trained with a set of training data with a target value, each. In the <a href=/blog/machine_learning/ensemblemethods target=_blank>first blog article</a>, the feature records and their associated target value have been introduced for the swissbib project at hand. The target value on a feature record declares wether the record is a record of a pair of duplicates or a record of a pair of uniques. Support Vector Machines are a popular method in the area of supervised learning, with its origins in the computer sciences community. In this blog, the results of a Support Vector Machine are presented. In Machine Learning, there are also methods for training artificial machines on data with missing target values. These methods are grouped as unsupervised learning, where k-means is a representative method. Both models, Support Vector Machine and k-means give some deeper insight into the underlying data.</p><p>In the <a href=/blog/machine_learning/ensemblemethods target=_blank>first blog article</a>, the notion of a feature record has been introduced. From a mathematical point of view one single feature record can be considered a point in an n-dimensional space, with n equal to the number of twenty features in the swissbib project at hand. The deduplication problem of swissbib is a classification task. Explicitly, the artificial machine is trained to assign each point in the feature space to one of the two target classes, either the target value pair of uniques or the target value pair of duplicates. During the training process, a Support Vector Machine searches a boundary which separates the records of pairs of uniques from the records of pairs of duplicates. If this boundary is useful it clusters the points of the feature space that belong to the same class. If the feature space is 2-dimensional, it is a plane and the boundary is a line. This line need not necessarily be straight but may have an arbitrary shape which may make its mathematical representation arbitrarily complicated. In an n-dimensional space, this boundary is called a <a href=https://en.wikipedia.org/wiki/Hyperplane target=_blank>hyperplane</a>. The best hyperplane for separating the records into its two classes may have a complicated mathematical representation. To avoid this issue and with the goal of separating the points with the help of a linear hyperplane, a Support Vector Machine can transform the feature space, instead. This transformation from a linear space to a non-linear space is done with a <a href=https://en.wikipedia.org/wiki/Kernel_method target=_blank>kernel transformation</a> of the machine. The kernel transformation ideally separates the data points of the two classes. This trick is called the <a href=https://datamites.com/blog/support-vector-machine-algorithm-svm-understanding-kernel-trick/ target=_blank>kernel trick</a>. (There are several blogs in the internet, explaining the kernel trick visually. Search for Images on &ldquo;kernel trick of support vector machine&rdquo; in Google.)</p><p>In the project described, a Support Vector Machine is trained with the help of swissbib training data, using <a href=https://en.wikipedia.org/wiki/Cross-validation_(statistics) target=_blank>cross-validation</a>. For the parameters of the classifier, a kernel with a <a href=https://en.wikipedia.org/wiki/Degree_of_a_polynomial target=_blank>polynomial transformation of third degree</a> is found to generate the best results. With this classifier, an accuracy value of 99.88% can be reached. This accuracy is lower than the best accuracy values of the best Random Forests model of the <a href=/blog/machine_learning/ensemblemethods/ target=_blank>first blog article</a>. It means explicitly 60 wrong predictions on a total of 51'886 validation records.</p><p>A Support Vector Machine predicts the belonging of a data point to a class according to a probability value in the range of the interval from 0 to 1. The threshold value of 0.5 is the separator between the two classes. If the Support Vector Machine calculates a probability value in the interval from 0 to 0.5, then the classifier model assigns the feature record to the class of pairs of uniques. If the classifier model calculates a probability value in the interval from 0.5 to 1, then the machine assigns the feature record to the class of pairs of duplicates. Figure 1 shows the distribution of the records for some part of swissbib training data. The green line in the figure represents the threshold of 0.5, separating the data into its two classes.</p><h2 id=a-hrefimagemlsvc_probabilityoptsvg-target_blankimg-style-width-100-height-100-srcimagemlsvc_probabilitypnga><a href=/image/ml/svc_probability.opt.svg target=_blank><img style=width:100%;height:100% src=/image/ml/svc_probability.png></a></h2><h2 id=figure-1-probability-distribution-of-swissbib-training-data>Figure 1. Probability distribution of swissbib training data</h2><br><br><p>Looking at figure 1, it is very interesting to observe the distance of the points from the classes separating threshold. It looks like most of the pairs of uniques lie on a line with a probability value of 1, while many of the pairs of duplicates lie on a line with a probability value of 0. These extreme points with probabilities at the probability boundaries 0 and 1 are the easy cases. More interesting are the points that have probability values between 1 and 0. These are the cases expressing some uncertainty. Even more interesting are the cases which are located on the wrong side of their class. These are the wrong predictions of the Support Vector Machine. Figure 1 shows some pairs of uniques in the domain area of duplicates and some pairs of duplicates in the domain area of uniques. These points have to be investigated deeper to understand why they are wrongly assigned. This task has to be done manually and will be subject of a later blog to come.</p><p>In spite of the wrong predictions, figure 1 proves that the Support Vector Machine trained is a useful model for predicting the class on swissbib data. There seems to be some criteria in the data that separate the two classes. Machine Learning offers several methods of unsupervised learning to investigate and eventually confirm this assumption. As an example, the capstone project uses the method of <a href=https://en.wikipedia.org/wiki/K-means_clustering target=_blank>k-means</a> for further analysing the data. This method tries to cluster data without any target value information, generating a number of k clusters. For the swissbib project at hand, k=2 is suggested, namely for the class of records of pairs of uniques and the other class of records of pairs of duplicates. After training a k-means model with k=2 on the training data where having removed the target values from the feature records for training the model, the points predicted by the model can be coloured subsequently according to their target values known in truth from the training data. Assigning the colour red to records of pairs of duplicates and the colour of blue to records of uniques to the predictions of the trained k-means model, generates the graph of figure 2. Looking at figure 2, it shows the red points well clustered and separated from the cluster of blue points.</p><h2 id=a-hrefimagemlkmeans_traindataoptsvg-target_blankimg-style-width-50-height-50-srcimagemlkmeans_traindatapnga><a href=/image/ml/kmeans_traindata.opt.svg target=_blank><img style=width:50%;height:50% src=/image/ml/kmeans_traindata.png></a></h2><h2 id=figure-2-k-means-clustering-on-training-data>Figure 2. k-means clustering on training data</h2><br><br><p>Comparing figure 1 with figure 2, it is interesting to observe, that independent of wether either a supervised learning method or an unsupervised learning method is used, the data allows a clear separability between the classes. The patterns in the data, allowing for separability is learnt when training the models with the training data. On the other hand, the separability is neither complete or absolute. There are points that are wrongly classified, wrongly according their class-belonging in the training data. There are blue dots in the red domain and vice versa red dots in the blue domain. Those wrongly classified feature records have to be investigated deeper, they are the subject of discussion with swissbib data experts. Both figures, though, confirm that the data has some properties that help separating pairs of uniques from pairs of duplicates.</p><p>This blog article offers some insight into the properties of swissbib training data. This insight can be deepened analysing the underlying models and its statements. With this view, the trained machines talk to humans illustrating their mathematical background in a compacted manner. Discussing these results of different aspects helps humans to improve their understanding of the data. Humans can learn from the models, they can learn from the trained machines. This aspect of interaction between the two entities humans and machines is an important aspect, hardly discussed in the debate on Machine Learning and artificial intelligence.</p><p>When talking about intelligence, the human brain is considered to be its domicile. The human brain is an incredibly powerful network of neurons and therefore, Machine Learning tries to find results with the help of networks that simulate the human brain. The next blog article will explain the results of a Neural Network.</p><p><a href=/blog/machine_learning/background_de>Einführungsartikel: warum beschäftigen wir uns mit Methoden des Maschinellen Lernens</a><br><a href=/blog/machine_learning/background_en>Introductory article: why do we deal with methods of machine learning</a><br><a href=/blog/machine_learning/ensemblemethods>Part1: ensemble methods</a><br><a href=/blog/machine_learning/neural_networks>Part3: neural networks</a></p><p><a href=https://www.linkedin.com/in/andreas-jud-2a39a770/ target=_blank>Author: Andreas Jud</a></p><div class=tags><a href=/tags/support-vector-machine><svg width="20" class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="currentcolor" d="M16 5l-.3125.28125L4.28125 16.8125l-.6875.6875.6875.71875 9.5 9.5.71875.6875.6875-.6875L26.71875 16.3125 27 16v-.40625V6 5H26 16.40625 16zm.84375 2H25v8.15625L14.5 25.59375 6.40625 17.5 16.84375 7zM22 9C21.447715 9 21 9.4477153 21 10 21 10.552285 21.447715 11 22 11S23 10.552285 23 10C23 9.4477153 22.552285 9 22 9z"/></svg>Support vector machine </a><a href=/tags/english><svg width="20" class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="currentcolor" d="M16 5l-.3125.28125L4.28125 16.8125l-.6875.6875.6875.71875 9.5 9.5.71875.6875.6875-.6875L26.71875 16.3125 27 16v-.40625V6 5H26 16.40625 16zm.84375 2H25v8.15625L14.5 25.59375 6.40625 17.5 16.84375 7zM22 9C21.447715 9 21 9.4477153 21 10 21 10.552285 21.447715 11 22 11S23 10.552285 23 10C23 9.4477153 22.552285 9 22 9z"/></svg>English </a><a href=/tags/2020><svg width="20" class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="currentcolor" d="M16 5l-.3125.28125L4.28125 16.8125l-.6875.6875.6875.71875 9.5 9.5.71875.6875.6875-.6875L26.71875 16.3125 27 16v-.40625V6 5H26 16.40625 16zm.84375 2H25v8.15625L14.5 25.59375 6.40625 17.5 16.84375 7zM22 9C21.447715 9 21 9.4477153 21 10 21 10.552285 21.447715 11 22 11S23 10.552285 23 10C23 9.4477153 22.552285 9 22 9z"/></svg>2020th</a></div></article></section><footer><div class="items-2 items"><section><h2>Recent Blog Posts</h2><ul><li><a href=https://swissbib.github.io/blog/machine_learning/neural_networks/>Exploring More Complex Patterns with Artificial Neural Networks</a> -
<time datetime=2020-11-11T20:00:00+02:00>Wednesday, Nov 11, 2020.</time></li><li><a href=https://swissbib.github.io/blog/software_development/swissbib_containerized/>Containerized environment for swissbib discovery</a> -
<time datetime=2020-08-23T08:50:09+02:00>Sunday, Aug 23, 2020.</time></li><li><a href=https://swissbib.github.io/blog/machine_learning/support_vector_machine/>What Humans Learn about the Data from a Support Vector Machine</a> -
<time datetime=2020-08-20T16:07:50+02:00>Thursday, Aug 20, 2020.</time></li><li><a href=https://swissbib.github.io/blog/machine_learning/ensemblemethods/>A Machine Learning Approach with Ensemble Methods</a> -
<time datetime=2020-07-19T13:48:19+02:00>Sunday, Jul 19, 2020.</time></li><li><a href=https://swissbib.github.io/blog/machine_learning/background_de/>Warum maschinelles Lernen im swissbib Projekt</a> -
<time datetime=2020-07-18T15:50:09+02:00>Saturday, Jul 18, 2020.</time></li><li><a href=https://swissbib.github.io/blog/machine_learning/background_en/>Why machine learning in the swissbib project</a> -
<time datetime=2020-07-18T15:50:09+02:00>Saturday, Jul 18, 2020.</time></li></ul></section><section><h2>Contact Us</h2><ul class=contact-us><li><a target=_blank href=mailto:swissbib-ub@unibas.ch rel=noopener><svg width="30" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M3 8V9 25v1H4 28h1V25 9 8H28 4 3zm4.3125 2h17.375L16 15.78125 7.3125 10zM5 10.875l10.4375 6.96875L16 18.1875l.5625-.34375L27 10.875V24H5V10.875z"/></svg><span>swissbib-ub [at] unibas [dot] ch</span></a></li><li><a target=_blank href=https://twitter.com/swissbib rel=noopener><svg width="30" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M28 8.557c-.883.392-1.832.656-2.828.775 1.017-.609 1.797-1.574 2.165-2.724-.951.564-2.005.974-3.127 1.195-.898-.957-2.178-1.555-3.594-1.555-2.719.0-4.924 2.205-4.924 4.924.0.386.044.762.127 1.122-4.092-.205-7.72-2.166-10.149-5.145C5.247 7.876 5.004 8.722 5.004 9.625c0 1.708.869 3.215 2.19 4.098-.807-.026-1.566-.247-2.23-.616.0.021.0.041.0.062.0 2.386 1.697 4.376 3.95 4.828C8.501 18.11 8.066 18.17 7.616 18.17c-.317.0-.626-.031-.926-.088.627 1.956 2.445 3.38 4.6 3.42-1.685 1.321-3.808 2.108-6.115 2.108-.397.0-.789-.023-1.175-.069 2.179 1.397 4.767 2.212 7.548 2.212 9.057.0 14.009-7.503 14.009-14.01.0-.213-.005-.426-.014-.637C26.505 10.411 27.34 9.544 28 8.557z"/></svg><span>twitter.com/swissbib</span></a></li></ul></section></div><div id=copyright>Last Updated -
<time datetime=2020-11-18T06:57:06+01:00>Wednesday, Nov 18, 2020.</time><br>Themed using <a href=https://github.com/hugoinaction/Eclectic target=_blank>Eclectic</a> by <a href=https://atishay.me target=_blank>Atishay</a></div></footer></body></html>